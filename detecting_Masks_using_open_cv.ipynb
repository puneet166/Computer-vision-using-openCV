{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "detecting Masks using open cv.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-wX3B6-oaHP"
      },
      "source": [
        "# **Face detection using opencv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSQrPYxPl0tc",
        "outputId": "f47e3e9b-caff-4930-d6a6-393028d7f388"
      },
      "source": [
        "from keras.models import load_model #for load model\n",
        "import cv2 #import open cv\n",
        "import numpy as np #import numpy "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTx6ALhil0to"
      },
      "source": [
        "model = load_model('model-017.model') #load the pretrainied classfication model\n",
        "\n",
        "face_clsfr=cv2.CascadeClassifier('haarcascade_frontalface_default.xml') # its xml file help us to detect face. all feature regarding face store in this xml file.\n",
        "\n",
        "\n",
        "source=cv2.VideoCapture(0) #VideoCapture this function use to open inbuild camera. if you want to use another object  for video use path . \n",
        "# these twos dic will be use further in program..\n",
        "labels_dict={0:'MASK',1:'NO MASK'} #its use further. if our model predict 0 mean  mask 1 mean no mask.\n",
        "color_dict={0:(0,255,0),1:(0,0,255)} # its for color if user doesnot wear mask display color would be 0,0,255 . if user wear mask display color will be 0,255,0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtaVqeRol0tw"
      },
      "source": [
        "while(True): # inifinte loop \n",
        "\n",
        "    ret,img=source.read() # read frames from videos\n",
        "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # here we are converting this 3 channel RBG image into single channel which is grey.\n",
        "# - why we convert it into grey chaneel.\n",
        "# becoz we knew when we process image with RBG channel it will take lot of time for processing.so fast processing we convert into 1 channel grey.\n",
        "    faces=face_clsfr.detectMultiScale(gray,1.3,5)   # detectMultiScale is the method which retuen 4 values from a images.that 4 values represent where the face in that particular images.\n",
        "# first aruguent we pass the image. where we want to identity the face.\n",
        "\n",
        "# face_classifier its a object that feature of that face detection store in this object.\n",
        "# if face not detected in that particular images that time this face_classifier retturn empty tuple.\n",
        "# if face detected it return 4 values first is x cordinate  y cordinate and height and width of faces.\n",
        "\n",
        "# When no faces detected, face_classifier returns and empty tuple\n",
        "    if faces is ():\n",
        "      print(\"No faces found\")\n",
        "\n",
        "    for x,y,w,h in faces:  # this loop fetch x cordinate y cordinate width and height of that face variable.\n",
        "    \n",
        "        face_img=gray[y:y+w,x:x+w] # this line detect only face from image and video frame and store in face_img variable with length or width of the face.\n",
        "        # and after detect only face we will give to our model for predict after some preprocessing.\n",
        "        resized=cv2.resize(face_img,(100,100)) #resize the face image into 100*100 pixels.\n",
        "        normalized=resized/255.0 #convert into scaling\n",
        "        reshaped=np.reshape(normalized,(1,100,100,1)) #reshape into 4 d for fit in our trained model.\n",
        "        result=model.predict(reshaped) #predict the output. it return 2d list as a output.\n",
        "\n",
        "        label=np.argmax(result,axis=1)[0] #convert 2d list into single class.class would be one from twos . mask wear or not\n",
        "      \n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[label],2) \n",
        "        #its for draw rectangle on the face with some arguments.\n",
        "        # 1.pass full image .\n",
        "        # 2.pass x and y cordinate mean which part we want to select(fetch) from image for draw rectangle.so here we are fetching only face from image..\n",
        "        # 3.pass value of x and y cordinate.\n",
        "        # 4.pass color of rectangle\n",
        "        # 5. 2 pass for draw rectange lines on x and y axis cordinate.\n",
        "\n",
        "        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1) #its same but with some changes.\n",
        "        cv2.putText(img, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2) #put some text on that image.\n",
        "        \n",
        "        \n",
        "        \n",
        "    cv2.imshow('LIVE',img) # here show the face mask detection on that image #Live is the label of that image\n",
        "    key=cv2.waitKey(1) # here its waitkey images will be hold and shoow untill and unless user doesnot press any keys.\n",
        "    \n",
        "    if(key==88): #if enter 88 it inifinte loop will exit.\n",
        "        break\n",
        "        \n",
        "cv2.destroyAllWindows() # after done all works here free and destroy the obeject.\n",
        "# its becoz avoid the hanging problems and lacling.\n",
        "source.release() #realse all sources."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}