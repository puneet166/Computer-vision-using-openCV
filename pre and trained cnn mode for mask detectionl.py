# -*- coding: utf-8 -*-
"""trained CNN model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g_sWh1DBA9Xs6hxMb-Q3Uk2S98jYTQne

Data preprocessing and prepare model
"""

import cv2,os #import opencv and os library

data_path='/content/drive/My Drive/datase' #path of the files
categories=os.listdir(data_path) #find the categories. how many categories availabe in particular folder.
labels=[i for i in range(len(categories))] #calculate the labels , labels start from 0 upto len of categories

label_dict=dict(zip(categories,labels)) #concatenate categories with label(some no) and store in label_dic

print(label_dict) #print
print(categories) #print
print(labels) #print

img_size=100 #we will convert image into 100*100 pixels
data=[] #empty list for insert image data after preprocessing.
target=[] #its list for label.


for category in categories: #iterate upto last categories.
    folder_path=os.path.join(data_path,category) #concatenate categories with directory... 
    img_names=os.listdir(folder_path) 
        
    for img_name in img_names: #iterate each images
        img_path=os.path.join(folder_path,img_name) 
        img=cv2.imread(img_path) #read each images from directories.

        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           
        #Coverting the image into gray scale
        resized=cv2.resize(gray,(img_size,img_size))
        #resizing the gray scale into 100x100, since we need a fixed common size for all the images in the dataset
        data.append(resized)
        target.append(label_dict[category])
        #appending the image and the label(categorized) into the list (dataset)

import numpy as np #import numpy array

data=np.array(data)/255.0 # perform feature scaling. for fast calculations.
data=np.reshape(data,(data.shape[0],img_size,img_size,1)) #reshape the images into 4d beacuse CNN support 4 d array as input.
target=np.array(target) #convert into numpy array, 

from keras.utils import np_utils

new_target=np_utils.to_categorical(target) #perform label encoding on target variable.

from keras.models import Sequential
from keras.layers import Dense,Activation,Flatten,Dropout
from keras.layers import Conv2D,MaxPooling2D
from keras.callbacks import ModelCheckpoint
#these all neccessory liberay for create deep learing model.

model=Sequential() #init the model

model.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
#The first CNN layer followed by Relu and MaxPooling layers

model.add(Conv2D(100,(3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
#The second convolution layer followed by Relu and MaxPooling layers

model.add(Flatten())
model.add(Dropout(0.5))
#Flatten layer to stack the output convolutions from second convolution layer
model.add(Dense(50,activation='relu'))
#Dense layer of 64 neurons
model.add(Dense(2,activation='softmax'))
#The Final layer with two outputs for two categories

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

from sklearn.model_selection import train_test_split# its library use for train and test spilt

train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1) #spilt data into train and test 90% training and 10% test

best_model = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto') #save best model in current directory.
history=model.fit(train_data,train_target,epochs=20,callbacks=[best_model],validation_split=0.2) #fit data into the model.

# training loss and validation loss
from matplotlib import pyplot as plt

plt.plot(history.history['loss'],'r',label='training loss')
plt.plot(history.history['val_loss'],label='validation loss')
plt.xlabel('# epochs')
plt.ylabel('loss')
plt.legend()
plt.show()

# training acuuracy and validation accuracy
plt.plot(history.history['accuracy'],'r',label='training accuracy')
plt.plot(history.history['val_accuracy'],label='validation accuracy')
plt.xlabel('# epochs')
plt.ylabel('loss')
plt.legend()
plt.show()